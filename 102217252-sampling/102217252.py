# -*- coding: utf-8 -*-
"""102217252

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1943j3Dkq8J268awwFjU9VsRUbcdAgu4t
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.preprocessing import normalize
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedShuffleSplit

url = "https://github.com/AnjulaMehto/Sampling_Assignment/raw/main/Creditcard_data.csv"
data = pd.read_csv(url)
data.head()

data.Class.value_counts() #This implies that our data is imbalanced

"""To balance the dataset, use SMOTE (Synthetic Minority Oversampling Technique)"""

# Splitting data into features and target
X = data.drop('Class', axis=1)
y = data['Class']

# Balancing the dataset
smote = SMOTE(random_state=42)
X_balanced, y_balanced = smote.fit_resample(X, y)

# Confirm the balance
print(y_balanced.value_counts())

resample = pd.concat([X_balanced, y_balanced], axis=1)
resample

Amount = normalize([data['Amount']])[0]
data['Amount'] = Amount
data = data.iloc[:, 1:]
data.head()

"""**Simple Random Sampling**"""

n = int((1.96 * 1.96 * 0.5 * 0.5) / (0.05**2))

SimpleSampling = resample.sample(n=n, random_state=42)
print("Shape of Simple Random Sampling Data:", SimpleSampling.shape)

X = SimpleSampling.drop('Class', axis=1)
y = SimpleSampling['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf_model = RandomForestClassifier(random_state=42)
lr_model = LogisticRegression()
svm_model = SVC(random_state=42)
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
knn_model = AdaBoostClassifier(random_state=42)

models = [rf_model, lr_model, svm_model, xgb_model, knn_model]
model_names = ['Random Forest', 'Logistic Regression', 'SVM', 'XGBoost', 'AdaBoost']

accuracies = []
for model, name in zip(models, model_names):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)
    print(f"{name} : {accuracy:.4f}")

best_model_idx = np.argmax(accuracies)
best_model_name = model_names[best_model_idx]
print(f"\nBest Model for Simple Random Sampling: {best_model_name} with Accuracy: {accuracies[best_model_idx]:.4f}")

"""**Systematic Sampling**"""

def systematic_sampling(data, step):
    return data.iloc[::step]

step_size = len(resample) // n
SystematicSampling = systematic_sampling(resample, step=step_size)
print("Shape of Systematic Sampling Data:", SystematicSampling.shape)

X = SystematicSampling.drop('Class', axis=1)
y = SystematicSampling['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

accuracies = []
for model, name in zip(models, model_names):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)
    print(f"{name} : {accuracy:.4f}")

best_model_idx = np.argmax(accuracies)
best_model_name = model_names[best_model_idx]
print(f"\nBest Model for Systematic Sampling: {best_model_name} with Accuracy: {accuracies[best_model_idx]:.4f}")

"""**Stratified Sampling**"""

sss = StratifiedShuffleSplit(n_splits=1, test_size=n, random_state=42)
for train_index, sample_index in sss.split(resample, resample['Class']):
    StratifiedSampling = resample.iloc[sample_index]

print("Shape of Stratified Sampling Data:", StratifiedSampling.shape)

X = StratifiedSampling.drop('Class', axis=1)
y = StratifiedSampling['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

accuracies = []
for model, name in zip(models, model_names):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)
    print(f"{name} : {accuracy:.4f}")

best_model_idx = np.argmax(accuracies)
best_model_name = model_names[best_model_idx]
print(f"\nBest Model for Stratified Sampling: {best_model_name} with Accuracy: {accuracies[best_model_idx]:.4f}")

"""**Cluster Sampling**"""

resample['Cluster'] = np.random.randint(0, 10, size=len(resample))
chosen_cluster = 3
ClusterSampling = resample[resample['Cluster'] == chosen_cluster]

print("Shape of Cluster Sampling Data:", ClusterSampling.shape)

X = ClusterSampling.drop(['Class', 'Cluster'], axis=1)
y = ClusterSampling['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

accuracies = []
for model, name in zip(models, model_names):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)
    print(f"{name} : {accuracy:.4f}")

best_model_idx = np.argmax(accuracies)
best_model_name = model_names[best_model_idx]
print(f"\nBest Model for Cluster Sampling: {best_model_name} with Accuracy: {accuracies[best_model_idx]:.4f}")

"""**Bootstrap Sampling**"""

def bootstrap_sampling(data, n_samples):
    return data.sample(n=n_samples, replace=True, random_state=42)

n_samples = n
BootstrapSampling = bootstrap_sampling(resample, n_samples)
print("Shape of Bootstrap Sampling Data:", BootstrapSampling.shape)

X = BootstrapSampling.drop('Class', axis=1)
y = BootstrapSampling['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

accuracies = []
for model, name in zip(models, model_names):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)
    print(f"{name} : {accuracy:.4f}")

best_model_idx = np.argmax(accuracies)
best_model_name = model_names[best_model_idx]
print(f"\nBest Model for Bootstrap Sampling: {best_model_name} with Accuracy: {accuracies[best_model_idx]:.4f}")